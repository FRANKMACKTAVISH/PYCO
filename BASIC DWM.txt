DataFrame

weatherFilePath = '/content/drive/MyDrive/DIU/Courses/Big-Data-and-IOT/lab-5/Weather.csv'

weather = practice.read.load(weatherFilePath, format='csv', InferSchema=True, header=True)
weather.show()

weather = weather.withColumnRenamed('province', 'city')
weather.show()

df = weather.toDF('code', 'city', 'date', 'avg_temp', 'min_temp', 'max_temp', 'precipitation', 'max_wind_speed', 'most_wind_direction', 'avg_relativer_humidity')
df.show()

df_temp= df.select('max_temp').show()

df_temp_sort = df.sort('max_temp')
df_temp_sort.show()

df_temp_filter = df_temp_sort.filter(df_temp_sort.max_temp>0)
df_temp_filter.show()

Window

weather_window = Window.partitionBy(['city']).orderBy(Function.desc('max_temp'))
weather.withColumn('rank', Function.rank().over(weather_window)).show()

weather.withColumn('lag', Function.lag('avg_relative_humidity', 4).over(weather_window)).show()


MapReduce

new_file_path = '/content/drive/MyDrive/DIU/Courses/Big-Data-and-IOT/lab-5/sample-text-file.txt'
map = practice.sparkContext.textFile(new_file_path).flatMap(lambda line: line.split())
map.collect()

map = map.map(lambda word: (word, 1))
map.collect()

map = map.sortByKey()
map.collect()

map.reduceByKey(lambda a,b: a+b).collect()